{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southwest-distinction",
   "metadata": {},
   "source": [
    "The following notebook will be split into 4 parts:\n",
    " - [Part 1](#Part1_UCID): Setup\n",
    " - [Part 2](#Part2_UCID): Exploratory Data Analysis\n",
    " - [Part 3](#Part3_UCID): Clustering\n",
    " - [Part 4](#Part4_UCID): Forecasting\n",
    " \n",
    "**Part 1:** Initial setup (importing relevant packages, setting up global hyperparameters, importing/cleaning our data set).\n",
    "\n",
    "**Part 2:** Exploratory data analysis that serves to act as the feature selection step by determining which features are ir/relevant.\n",
    "\n",
    "**Part 3:** Clustering days based on a similarity metric.\n",
    "\n",
    "**Part 4:** Forecasting on a per-cluster basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-image",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Part 1: Setup <a id=\"Part1_UCID\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-raise",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## 1.1: Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-boxing",
   "metadata": {},
   "source": [
    "**Step 1:** Import the relevant packages and set Seaborn/Matplotlib hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "import holidays\n",
    "import os\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import umap\n",
    "\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, ConvLSTM2D, Dense, Flatten, MaxPooling1D, RepeatVector, TimeDistributed, MaxPooling2D, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tqdm import notebook\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "plt.rcParams[\"axes.labelsize\"] = 26\n",
    "plt.rcParams[\"axes.titlesize\"] = 26\n",
    "plt.rcParams[\"figure.figsize\"] = 16, 10\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"xtick.labelsize\"] = 22\n",
    "plt.rcParams[\"ytick.labelsize\"] = 22\n",
    "plt.rcParams[\"legend.fontsize\"] = 22\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "tensorflow.random.set_seed(3141589)\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-pizza",
   "metadata": {},
   "source": [
    "**Step 2:** Define the location of our data as well as the relevant columns that we would like to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-christian",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_UCID = [\n",
    "    \"Date\",\n",
    "    \"Time\",\n",
    "    \"Global_active_power\",\n",
    "    \"Global_reactive_power\",\n",
    "    \"Voltage\",\n",
    "    \"Global_intensity\",\n",
    "    \"Sub_metering_1\",\n",
    "    \"Sub_metering_2\",\n",
    "    \"Sub_metering_3\",\n",
    "]\n",
    "\n",
    "data_directory_UCID = os.path.join(\"Data\", \"UCI\")\n",
    "data_directory_Solcast = os.path.join(\"Data\", \"Solcast_UCID\")\n",
    "\n",
    "house = \"household_power_consumption.txt\"\n",
    "solcast_15 = \"Solcast_UCID_15.csv\"\n",
    "\n",
    "file_destination_UCID = os.path.join(data_directory_UCID, house)\n",
    "file_destination_Solcast = os.path.join(data_directory_Solcast, solcast_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-middle",
   "metadata": {},
   "source": [
    "**Step 3:** Read in the data and save it to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID = pd.read_csv(file_destination_UCID, parse_dates=True,  delimiter = \";\", usecols=cols_UCID)\n",
    "\n",
    "df_UCID[\"DT\"] = df_UCID[\"Date\"].str.cat(df_UCID[\"Time\"], sep=\" \")\n",
    "df_UCID[\"DT\"] = pd.to_datetime(df_UCID[\"DT\"], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "df_UCID = df_UCID.reset_index()\n",
    "df_UCID = df_UCID.set_index(\"DT\")\n",
    "df_UCID.index = pd.to_datetime(df_UCID.index)\n",
    "\n",
    "cols_NA = [\n",
    "    \"index\",\n",
    "    \"Date\",\n",
    "    \"Time\",\n",
    "]\n",
    "\n",
    "df_UCID.drop(cols_NA, axis=1, inplace=True)\n",
    "\n",
    "cols = df_UCID.columns\n",
    "df_UCID[cols] = df_UCID[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "cols_UCID.remove(\"Date\")\n",
    "cols_UCID.remove(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Solcast = pd.read_csv(file_destination_Solcast, index_col=0, parse_dates=True)\n",
    "\n",
    "df_Solcast.index = df_Solcast.index.rename(\"Time\")\n",
    "df_Solcast.index = pd.to_datetime(df_Solcast.index).tz_localize(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-float",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## 1.2: Scale the data in the dataframe(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-telling",
   "metadata": {},
   "source": [
    "**Step 1.1:** Scale the data in a range between 0 and 1 (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax_UCID = MinMaxScaler()\n",
    "# minmax_Solcast = MinMaxScaler()\n",
    "\n",
    "# df_UCID[cols_UCID] = minmax_UCID.fit_transform(df_REFIT[cols_UCID])\n",
    "# df_Solcast[cols_Solcast] = minmax_Solcast.fit_transform(df_Solcast[cols_Solcast])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-farming",
   "metadata": {},
   "source": [
    "**Step 1.2:** Standardize the data by removing the mean and scaling to unit variance (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardscale_UCID = StandardScaler()\n",
    "# standardscale_Solcast = StandardScaler()\n",
    "\n",
    "# df_UCID[cols_UCID] = standardscale_UCID.fit_transform(df_UCID[cols_UCID])\n",
    "# df_Solcast[cols_Solcast] = standardscale_Solcast.fit_transform(df_Solcast[cols_Solcast])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-aquarium",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## 1.3: Merge the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-appraisal",
   "metadata": {},
   "source": [
    "**Step 1:** Create a copy of our REFIT dataframe that is resampled into a resolution of 15 minutes and drop any days that contain an incomplete number of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled = df_UCID.resample(\"15min\").mean()\n",
    "df_UCID_resampled = df_UCID_resampled.dropna()\n",
    "\n",
    "mask = df_UCID_resampled.groupby(df_UCID_resampled.index.date).size()\n",
    "mask = mask[mask < 96].index.to_list()\n",
    "\n",
    "df_UCID_resampled = df_UCID_resampled[~df_UCID_resampled.index.floor(\"D\").isin(mask)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-ontario",
   "metadata": {},
   "source": [
    "**Step 2:** Create a third dataframe that is the result of merging the Solcast dataframe with the REFIT dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Merged = pd.merge(left=df_Solcast, left_on=df_Solcast.index, right=df_UCID_resampled, right_on=df_UCID_resampled.index)\n",
    "\n",
    "cols_Merged = [\n",
    "    \"PeriodStart\",\n",
    "    \"Period\",\n",
    "    \"Global_reactive_power\",\n",
    "    \"Voltage\",\n",
    "    \"Global_intensity\",\n",
    "    \"Sub_metering_1\",\n",
    "    \"Sub_metering_2\",\n",
    "    \"Sub_metering_3\",\n",
    "]\n",
    "\n",
    "df_Merged.drop(cols_Merged, axis=1, inplace=True)\n",
    "df_Merged.rename(columns={\"key_0\": \"Time\"}, inplace=True)\n",
    "df_Merged = df_Merged.set_index(\"Time\")\n",
    "df_Merged.index = pd.to_datetime(df_Merged.index)\n",
    "df_Merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-forth",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## 1.4: Append temporal features to our merged dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-commission",
   "metadata": {},
   "source": [
    "**Step 1:** Append public holidays to our merged dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "France_holidays = holidays.France()\n",
    "df_Merged.insert(0, \"Holiday\", [1 if str(val).split()[0] in France_holidays else 0 for val in df_Merged.index.date])\n",
    "df_Merged[\"Holiday\"] = df_Merged[\"Holiday\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-circulation",
   "metadata": {},
   "source": [
    "**Step 2:** Define day of the year ranges for each of the seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "spring = range(60, 152)\n",
    "summer = range(152, 244)\n",
    "fall = range(244, 336)\n",
    "\n",
    "def season(doy):\n",
    "    if doy in spring:\n",
    "        return \"0\"\n",
    "    if doy in summer:\n",
    "        return \"1\"\n",
    "    if doy in fall:\n",
    "        return \"2\"\n",
    "    else:\n",
    "        return \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-sponsorship",
   "metadata": {},
   "source": [
    "**Step 3:** Append temporal data to our merged dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Merged.insert(0, \"Year\", df_Merged.index.year)\n",
    "df_Merged.insert(1, \"Month\", df_Merged.index.month)\n",
    "df_Merged.insert(3, \"Day\", df_Merged.index.day)\n",
    "df_Merged.insert(4, \"Hour\", df_Merged.index.hour)\n",
    "df_Merged.insert(5, \"Minute\", df_Merged.index.minute)\n",
    "df_Merged.insert(6, \"Weekday\", df_Merged.index.weekday)\n",
    "df_Merged.insert(7, \"Season\", df_Merged.index.dayofyear.map(season))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30e2b5-7ae3-4d2c-9874-c2de80d9115f",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Miscellaneous functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d73f9-cc9a-4655-8c99-de1fc1a2553b",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 1) Augmented Dickey–Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da5d68-83c1-4445-bd1b-a7115876e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adfuller_test(series, signif=0.05, name=\"\"):\n",
    "    r = adfuller(series, autolag=\"AIC\")\n",
    "    output = {\"test_statistic\": round(r[0], 4), \"pvalue\": round(r[1], 4), \"n_lags\": round(r[2], 4), \"n_obs\": r[3]}\n",
    "    p_value = output[\"pvalue\"]\n",
    "\n",
    "    def adjust(val, length=6):\n",
    "        return str(val).ljust(length)\n",
    "\n",
    "    print(f'      Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", \"-\" * 47)\n",
    "    print(f\" Null Hypothesis: Data has unit root. Non-Stationary.\")\n",
    "    print(f\" Significance Level    = {signif}\")\n",
    "    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n",
    "    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n",
    "\n",
    "    for key, val in r[4].items():\n",
    "        print(f\" Critical value {adjust(key)} = {round(val, 3)}\")\n",
    "    if p_value <= signif:\n",
    "        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n",
    "        print(f\" => Series is Stationary.\")\n",
    "    else:\n",
    "        print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n",
    "        print(f\" => Series is Non-Stationary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b031aee-d36d-4441-a6db-19256cb0b597",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 2) Augmented Dickey–Fuller test w/plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c3c6e-5efa-44ae-a7b4-e4bbd22114ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(series, signif=0.05, name=\"\", ylabel=\"\"):\n",
    "    def adjust(val, length=6):\n",
    "        return str(val).ljust(length)\n",
    "\n",
    "    rolmean = series.rolling(12).mean()\n",
    "    rolstd = series.rolling(12).std()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    series.plot(ax=ax, alpha=0.5)\n",
    "    rolmean.plot(ax=ax, alpha=0.7)\n",
    "    rolstd.plot(ax=ax, alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlim(left=0, right=len(series))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Rolling Mean & Standard Deviation\")\n",
    "    plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "\n",
    "    leg = plt.legend()\n",
    "    leg.get_texts()[0].set_text(name)\n",
    "    leg.get_texts()[1].set_text(\"Rolling Mean\")\n",
    "    leg.get_texts()[2].set_text(\"Rolling STD\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=False)\n",
    "\n",
    "    adfuller_test(series, 0.05, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139dca84-eddf-4b6f-9989-d2868f8877aa",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 3) Granger Causality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7c15d-931b-4837-8bed-6bbd78358467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grangers_causation_matrix(data, variables, test=\"ssr_chi2test\", maxlag=12, verbose=False):\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = ([round(test_result[i + 1][0][test][1], 2) for i in range(maxlag)])\n",
    "            if verbose:\n",
    "                print(f\"Y = {r}, X = {c}, P Values = {p_values}\")\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + \"_x\" for var in variables]\n",
    "    df.index = [var + \"_y\" for var in variables]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f81f2a-a75b-4179-8921-8fd51bffcc02",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 4) Determine which highly correlated independent variables have a stronger correlation with our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d6c5b-d23e-4f55-bfb4-dc38158f6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df, threshold, target_variable):\n",
    "    col_corr = set()\n",
    "    corr_matrix = df.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                rowname = corr_matrix.index[j]\n",
    "                cor1 = abs(df[colname].corr(target_variable))\n",
    "                cor2 = abs(df[rowname].corr(target_variable))\n",
    "                if  cor1 > cor2:\n",
    "                    col_corr.add(corr_matrix.index[j])\n",
    "                else:\n",
    "                    col_corr.add(corr_matrix.columns[i])\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee79f04-4652-4513-98f1-4931c6aecde1",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 5) Reshape correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d93aaa-8fad-4d42-80fe-b2be5964919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_corr(df):\n",
    "    df_corr = df.corr().stack().reset_index()\n",
    "    df_corr.columns = [\"Feature 1\", \"Feature 2\", \"Correlation\"]\n",
    "    mask_dups = (df_corr[[\"Feature 1\", \"Feature 2\"]].apply(frozenset, axis=1).duplicated()) | (df_corr[\"Feature 1\"] == df_corr[\"Feature 2\"])\n",
    "    df_corr = df_corr[~mask_dups]\n",
    "\n",
    "    return df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa8ba2-366a-4e6d-b4cd-bf546674f07a",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 6) Forecasting accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f79295-2773-41f1-877f-c32328305c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_accuracy(forecast, actual):\n",
    "    mape = np.round(np.mean(np.abs(forecast - actual) / np.abs(actual)) * 100, 2)\n",
    "    mae = np.round(np.mean(np.abs(forecast - actual)), 2)\n",
    "    rmse = np.round(np.mean((forecast - actual) ** 2) ** 0.5, 2)\n",
    "\n",
    "    print(\"Forecasting accuracy metrics:\")\n",
    "    print(f\"\\t - MAPE = {mape}%\")\n",
    "    print(f\"\\t - MAE = {mae}\")\n",
    "    print(f\"\\t - RMSE = {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268b3b8-f6d4-4944-bf4f-0308272d1882",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 7) Reshape data into a suitable format for single step forecasting using our CNN-LSTM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ebaeb-4067-4e45-a2a3-0fbe44151881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_Supervised(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i : (i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd4a6f3-fd41-4ab1-bd86-c24c367ee648",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 8) Reshape data into a suitable format for multi-step forecasting using our CNN-LSTM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ace9d4-58f2-4367-8461-d9f61ccb2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_Supervised_ms(ts: np.array, lag=1, n_ahead=1, target_index=0) -> tuple:\n",
    "    n_features = ts.shape[1]\n",
    "    X, Y = [], []\n",
    "\n",
    "    if len(ts) - lag <= 0:\n",
    "        X.append(ts)\n",
    "    else:\n",
    "        for i in range(len(ts) - lag - n_ahead):\n",
    "            Y.append(ts[(i + lag) : (i + lag + n_ahead), target_index])\n",
    "            X.append(ts[i : (i + lag)])\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "    X = np.reshape(X, (X.shape[0], lag, n_features))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-strengthening",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Part 2: Exploratory Data Analysis <a id=\"Part2_UCID\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-measurement",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## 2.1: Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-gasoline",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 2.1.1: Line plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-substance",
   "metadata": {},
   "source": [
    "**Step 1:** Create a copy of our REFIT dataframe and reformat the index into a string so as to make sure that Matplotlib does not automatically interpolate missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled_c = df_UCID_resampled.copy()\n",
    "df_UCID_resampled_c.index = df_UCID_resampled_c.index.strftime(\"%d-%m-%y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-parameter",
   "metadata": {},
   "source": [
    "**Step 2:** Drop all columns barre the `Aggregate` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_UCID_c = cols_UCID.copy()\n",
    "cols_UCID_c.remove(\"Global_active_power\")\n",
    "df_UCID_resampled_c.drop(cols_UCID_c, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-diesel",
   "metadata": {},
   "source": [
    "**Step 3:** Plot the aggregate power consumption over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_UCID_resampled_c[\"Global_active_power\"].plot(ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Aggregate Power Consumption (Watts)\")\n",
    "ax.set_xlim(left=-5, right=len(df_UCID_resampled_c) + 5)\n",
    "ax.set_ylim(bottom=df_UCID_resampled_c[\"Global_active_power\"].min())\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-weight",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 2.1.2: Count plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-sweet",
   "metadata": {},
   "source": [
    "**Step 1:** Visualize the number of samples per day of the week over the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Merged_c = df_Merged.copy()\n",
    "df_Merged_c.insert(0, \"Weekday_name\", df_Merged.index.day_name())\n",
    "\n",
    "ax = sns.countplot(\n",
    "    x=df_Merged_c[\"Weekday_name\"],\n",
    "    data=df_Merged_c,\n",
    "    palette=\"icefire\",\n",
    "    order=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"],\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Weekday\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-return",
   "metadata": {},
   "source": [
    "**Step 2:** Visualize the number of samples per month over the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Merged_c = df_Merged.copy()\n",
    "df_Merged_c.insert(0, \"Month_name\", df_Merged.index.month_name())\n",
    "\n",
    "ax = sns.countplot(\n",
    "    x=df_Merged_c[\"Month_name\"],\n",
    "    data=df_Merged_c,\n",
    "    palette=\"icefire\",\n",
    "    order=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"],\n",
    ")\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-candle",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 2.1.3: Stationarity plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-analyst",
   "metadata": {},
   "source": [
    "**Step 1:** Test for stationarity and plot the result using the pre-defined `test_stationarity` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationarity(df_UCID_resampled_c, 0.05, \"Global_active_power\", \"Aggregate Power Consumption (Watts)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-given",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 2.1.4: Box and whisker plots/outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-editor",
   "metadata": {},
   "source": [
    "**Step 1:** Box and whiskers plot for the aggregate as well as each of the IAM readings grouped by the months of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(cols_UCID), 1, figsize=(16, 10 * (len(cols_UCID))), sharex=True)\n",
    "\n",
    "for col, ax in zip([*cols_UCID], axs):\n",
    "    sns.boxplot(\n",
    "        data=df_UCID,\n",
    "        x=df_UCID.index.month_name(),\n",
    "        y=col,\n",
    "        ax=ax,\n",
    "        order=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"],\n",
    "    )\n",
    "    ax.set_title(col)\n",
    "    ax.xaxis.set_label_text(\"\")\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-publicity",
   "metadata": {},
   "source": [
    "**Step 2:** We remove outliers that are 3 standard deviations away from the mean and repeat **step 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_UCID[(np.abs(stats.zscore(df_UCID[\"Global_active_power\"], nan_policy=\"omit\")) < 3)]\n",
    "print(f\"Number of outliers: {(len(df_UCID) - len(df_out))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_UCID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-biotechnology",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(cols_UCID), 1, figsize=(16, 10 * (len(cols_UCID))), sharex=True)\n",
    "\n",
    "for col, ax in zip([*cols_UCID], axs):\n",
    "    sns.boxplot(\n",
    "        data=df_out,\n",
    "        x=df_out.index.month_name(),\n",
    "        y=col,\n",
    "        ax=ax,\n",
    "        order=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"],\n",
    "    )\n",
    "    ax.xaxis.set_label_text(\"\")\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-motorcycle",
   "metadata": {},
   "source": [
    "**Step 2.1:** Purely for the global active power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(\n",
    "    data=df_out,\n",
    "    x=df_out.index.month_name(),\n",
    "    y=df_out[\"Global_active_power\"],\n",
    "    order=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"],\n",
    ")\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Aggregate Power Consumption (Watts)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-ballot",
   "metadata": {},
   "source": [
    "**Step 3:** Box and whiskers plot for the aggregate as well as each of the IAM readings over the entirety of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data=df_out, ax=ax)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-chance",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## 2.2: Time series decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-pursuit",
   "metadata": {},
   "source": [
    "**Step 1:** Create a copy of our REFIT dataframe and reformat the index into a string so as to make sure that Matplotlib does not automatically interpolate missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled_c = df_UCID_resampled.copy()\n",
    "df_UCID_resampled_c.index = df_UCID_resampled_c.index.strftime(\"%d-%m-%y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-ethernet",
   "metadata": {},
   "source": [
    "**Step 2:** Drop all columns barre the `Aggregate` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_UCID_c = cols_UCID.copy()\n",
    "cols_UCID_c.remove(\"Global_active_power\")\n",
    "df_UCID_resampled_c.drop(cols_UCID_c, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-sauce",
   "metadata": {},
   "source": [
    "**Step 3:** Define a period of 1 year (as an example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled_c = df_UCID_resampled_c.loc[\"01-01-07 00:00:00\":\"01-01-08 00:00:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-louisiana",
   "metadata": {},
   "source": [
    "**Step 4:** Perform time series decomposition using LOESS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = (24 * 60) // 15\n",
    "stl_decompose_result = STL(df_UCID_resampled_c, period=freq).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-ceiling",
   "metadata": {},
   "source": [
    "**Step 5:** Separate/plot the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = stl_decompose_result.observed\n",
    "trend = stl_decompose_result.trend.to_frame()\n",
    "seasonal = stl_decompose_result.seasonal.to_frame()\n",
    "noise = stl_decompose_result.resid.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, sharex=True)\n",
    "\n",
    "observed.plot(ax=axs[0], title=\"Observed\")\n",
    "trend.plot(ax=axs[1], title=\"Trend\")\n",
    "seasonal.plot(ax=axs[2], title=\"Seasonal\")\n",
    "noise.plot(ax=axs[3], title=\"Noise\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xlim(0, right=len(observed))\n",
    "    ax.get_legend().remove()\n",
    "    ax.title.set_size(22)\n",
    "\n",
    "fig.text(0.03, 0.6, \"Aggregate Power Consumption (Kilowatts)\", fontsize=\"22\", va=\"center\", rotation=\"vertical\")\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-identification",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## 2.3: Causality and correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-tolerance",
   "metadata": {},
   "source": [
    "**Step 1:** Perform the Augmented Dicky-Fuller test to determine whether our time series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, column in df_Merged.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-medicare",
   "metadata": {},
   "source": [
    "**Step 2:** Check for autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df_UCID_resampled[\"Global_active_power\"], lags=192, zero=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-kentucky",
   "metadata": {},
   "source": [
    "**Step 3:** Check for partial autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(df_UCID_resampled[\"Global_active_power\"], lags=96, zero=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-renewal",
   "metadata": {},
   "source": [
    "**Step 4:** Check for highly correlated features in the Solcast dataframe and drop them from our merged dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_correlated = correlation(df_Solcast, 0.7, df_Merged.Global_active_power)\n",
    "A = len(df_Merged.columns)\n",
    "print(highly_correlated)\n",
    "#df_Merged.drop(highly_correlated, axis=1, inplace=True)\n",
    "B = len(df_Merged.columns) - len(highly_correlated)\n",
    "print(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-theme",
   "metadata": {},
   "source": [
    "**Step 5:** Estimate mutual information of our independent variables on our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (df_Merged.loc[:, df_Merged.columns != \"Global_active_power\"], df_Merged[\"Global_active_power\"])\n",
    "mutual_info = mutual_info_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X.columns\n",
    "mutual_info = mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=mutual_info.values, y=mutual_info.index, palette=\"icefire\")\n",
    "ax.set_xlabel(\"Mutual information\")\n",
    "ax.set_ylabel(\"Independent variable\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-benchmark",
   "metadata": {},
   "source": [
    "**Step 6:** Granger causality test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = grangers_causation_matrix(df_Merged, variables = df_Merged.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm2 = gm.transpose()[\"Global_active_power_y\"].iloc[0:18].to_frame()\n",
    "ax = sns.heatmap(gm2, mask=gm2 < 0.05, annot=True, fmt=\".2f\", square=True, cmap=\"rocket_r\", vmin=0.0, vmax=1.0)\n",
    "ax2 = sns.heatmap(gm2, mask=gm2 >= 0.05, annot=True, fmt=\".2f\", square=True, cmap=\"rocket_r\", vmin=0.0, vmax=1.0, annot_kws={\"weight\": \"bold\"}, cbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(gm.transpose(), annot=True, fmt=\".2f\", square=True, cmap=\"rocket_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-nickname",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Part 3: Clustering <a id=\"Part3_UCID\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-sleeping",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## 3.1: Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-solution",
   "metadata": {},
   "source": [
    "**Step 1:** Create a copy of our REFIT dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled_c = df_UCID_resampled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-measurement",
   "metadata": {},
   "source": [
    "**Step 2:** Drop all columns barre the `Global_active_power` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_UCID_c = cols_UCID.copy()\n",
    "cols_UCID_c.remove(\"Global_active_power\")\n",
    "df_UCID_resampled_c.drop(cols_UCID_c, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-disabled",
   "metadata": {},
   "source": [
    "**Step 3:** Reshape our dataframe as 96 columns that represent the 96 15-minute chunks of each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled_c.index = pd.MultiIndex.from_arrays([df_UCID_resampled_c.index.date, df_UCID_resampled_c.index.time], names=[\"Date\", \"Time\"])\n",
    "df_UCID_resampled_c = df_UCID_resampled_c.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-thriller",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 3.1.1: Statistical parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-leeds",
   "metadata": {},
   "source": [
    "**Step 1:** Split our day into 5 periods:\n",
    " - `LEEM`: Late evening/early morning (23:30-06:00)\n",
    " - `MR`: Morning (06:00-11:00)\n",
    " - `LMAF`: Late morning/afternoon (11:00-15:00)\n",
    " - `LAEE`: Late afternoon/early evening (15:00-20:30)\n",
    " - `EV`: Evening (20:30-23:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEEM = df_UCID_resampled_c.iloc[:, np.r_[0:24, 92:96]]\n",
    "MR = df_UCID_resampled_c.iloc[:, 24:45]\n",
    "LMAF = df_UCID_resampled_c.iloc[:, 44:61]\n",
    "LAEE = df_UCID_resampled_c.iloc[:, 60:83]\n",
    "EV = df_UCID_resampled_c.iloc[:, 82:95]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-wagner",
   "metadata": {},
   "source": [
    "**Step 2:** Create a new dataframe that consists of the mean, min, max and standard deviation of each of our 5 periods per day. We now represent each day with 20 variables rather than 96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SP = LEEM.mean(axis=1).to_frame(name=\"LEEM_Mean\")\n",
    "df_SP.insert(len(df_SP.columns), \"LEEM_Min\", LEEM.min(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LEEM_Max\", LEEM.max(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LEEM_STD\", LEEM.std(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"MR_Mean\", MR.mean(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"MR_Min\", MR.min(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"MR_Max\", MR.max(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"MR_STD\", MR.std(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LMAF_Mean\", LMAF.mean(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LMAF_Min\", LMAF.min(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LMAF_Max\", LMAF.max(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LMAF_STD\", LMAF.std(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LAEE_Mean\", LAEE.mean(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LAEE_Min\", LAEE.min(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LAEE_Max\", LAEE.max(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"LAEE_STD\", LAEE.std(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"EV_Mean\", EV.mean(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"EV_Min\", EV.min(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"EV_Max\", EV.max(axis=1))\n",
    "df_SP.insert(len(df_SP.columns), \"EV_STD\", EV.std(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-stadium",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 3.1.2: tSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-natural",
   "metadata": {},
   "source": [
    "**Step 1:** Apply tSNE to our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = TSNE(random_state=3141589, perplexity=np.power(len(df_UCID_resampled_c), 0.5).astype(int), learning_rate=550, n_iter=5000).fit_transform(df_SP)\n",
    "projection = TSNE(random_state=3141589).fit_transform(projection)\n",
    "plt.scatter(*projection.T)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-meter",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## 3.2: HDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-booking",
   "metadata": {},
   "source": [
    "**Step 1:** Define our HDBSCAN clusterer with the appropriate hyperparameters and fit it to our 2-dimensional projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "HDB = hdbscan.HDBSCAN(min_cluster_size=(len(df_UCID_resampled_c) // 10), min_samples=15)\n",
    "HDB = HDB.fit(projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "HDB.condensed_tree_.plot(select_clusters=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-photographer",
   "metadata": {},
   "source": [
    "**Step 2:** Plot/visualize our clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = HDB.labels_\n",
    "labels = [label + 1 for label in labels]\n",
    "n_clusters = len(set(labels)) - (1 if 0 in labels else 0)\n",
    "n_noise = list(labels).count(0)\n",
    "core_samples_mask = np.zeros_like(labels, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Set1(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == 0:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "    class_member_mask = labels == k\n",
    "\n",
    "    xy = projection[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], \"o\", markerfacecolor=tuple(col), markeredgecolor=\"k\", markersize=14)\n",
    "\n",
    "    xy = projection[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], \"o\", markerfacecolor=tuple(col), markeredgecolor=\"k\", markersize=6)\n",
    "plt.title(\"Estimated number of clusters: %d\" % n_clusters)\n",
    "plt.show()\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise)\n",
    "print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(projection, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-newspaper",
   "metadata": {},
   "source": [
    "**Step 3:** Plot/visualize the average pattern per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled_c[\"Labels\"] = labels\n",
    "Cx = []\n",
    "\n",
    "for i in range(0, n_clusters + 1):\n",
    "    if(i == 0):\n",
    "        Cx.append(\"C-Noise\")\n",
    "    else:\n",
    "        Cx.append(f\"C\" + str(i))\n",
    "    globals()[\"C\" + str(i)] = (df_UCID_resampled_c.loc[df_UCID_resampled_c[\"Labels\"] == i]).mean(axis=0)\n",
    "    globals()[\"C\" + str(i)] = globals()[\"C\" + str(i)].reset_index()\n",
    "    globals()[\"C\" + str(i)].drop(\"level_0\", axis=1, inplace=True)\n",
    "    globals()[\"C\" + str(i)].drop(globals()[\"C\" + str(i)].tail(1).index, inplace=True)\n",
    "    globals()[\"C\" + str(i)][\"Time\"] = globals()[\"C\" + str(i)][\"Time\"].astype(\"str\")\n",
    "    globals()[\"C\" + str(i)][\"Time\"] = pd.to_datetime(globals()[\"C\" + str(i)][\"Time\"])\n",
    "    globals()[\"C\" + str(i)] = globals()[\"C\" + str(i)].set_index(\"Time\")\n",
    "    globals()[\"C\" + str(i)].index = globals()[\"C\" + str(i)].index.strftime(\"%H:%M:%S\")\n",
    "    globals()[\"C\" + str(i)] = globals()[\"C\" + str(i)].rename(columns={0: \"Aggregate\"})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(0, n_clusters + 1):\n",
    "    globals()[\"C\" + str(i)].plot(ax=ax, color=colors[i])\n",
    "\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Aggregate Power Consumption (Watts)\")\n",
    "ax.set_xlim(left=0, right=95)\n",
    "plt.legend([*Cx], loc=\"best\", fontsize=18)\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled_c.insert(0, \"Month_name\", df_UCID_resampled_c.index.month_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(\n",
    "    x=\"Month_name\",\n",
    "    hue=\"Labels\",\n",
    "    data=df_UCID_resampled_c,\n",
    "    palette=colors,\n",
    "    order=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"],\n",
    ")\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UCID_resampled_c.insert(0, \"Day_name\", df_UCID_resampled_c.index.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(\n",
    "    x=\"Day_name\",\n",
    "    hue=\"Labels\",\n",
    "    data=df_UCID_resampled_c,\n",
    "    palette=colors,\n",
    "    order=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"],\n",
    ")\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation=60)\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-yemen",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Part 4: Forecasting <a id=\"Part4_UCID\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_Merge = df_UCID_resampled_c.loc[df_UCID_resampled_c[\"Labels\"] == 1].copy()\n",
    "C1_Merge = C1_Merge.stack().reset_index()\n",
    "C1_Merge[\"Date\"] = C1_Merge[\"Date\"].astype(\"str\")\n",
    "C1_Merge[\"Time\"] = C1_Merge[\"Time\"].astype(\"str\")\n",
    "C1_Merge[\"DT\"] = C1_Merge[\"Date\"].str.cat(C1_Merge[\"Time\"], sep=\" \")\n",
    "\n",
    "cols_NA = [\n",
    "    \"Date\",\n",
    "    \"Time\",\n",
    "    \"Labels\",\n",
    "]\n",
    "\n",
    "C1_Merge.drop(cols_NA, axis=1, inplace=True)\n",
    "C1_Merge[\"DT\"] = pd.to_datetime(C1_Merge[\"DT\"])\n",
    "C1_Merge = C1_Merge.set_index(\"DT\")\n",
    "Test = df_Merged.reindex(C1_Merge.index)\n",
    "Test = Test.dropna()\n",
    "Test[\"Holiday\"] = Test[\"Holiday\"].astype('int32')\n",
    "Test[\"Season\"] = Test[\"Season\"].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = (24 * 60) // 15\n",
    "stl_decompose_result = STL(Test.Global_active_power, period=freq).fit()\n",
    "Test.insert(len(Test.columns), \"Trend\", stl_decompose_result.trend.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "Test[Test.columns] = scaler.fit_transform(Test[Test.columns])\n",
    "scaler.min_, scaler.scale_ = scaler.min_[len(Test.columns) - 1], scaler.scale_[len(Test.columns) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 24\n",
    "Split = len(Test)\n",
    "s_Train = Test.iloc[0 : int(Split * 0.6)]\n",
    "s_Val = Test.iloc[int(Split * 0.6): int(Split * 0.8)]\n",
    "s_Test = Test.iloc[int(Split * 0.8) :]\n",
    "\n",
    "X_train, Y_train = to_Supervised(s_Train, s_Train.Trend, time_steps)\n",
    "X_val, Y_val = to_Supervised(s_Val, s_Val.Trend, time_steps)\n",
    "X_test, Y_test = to_Supervised(s_Test, s_Test.Trend, time_steps)\n",
    "\n",
    "X_train = X_train.reshape(-1, 24, 14, 2, 1)\n",
    "X_val = X_val.reshape(-1, 24, 14, 2, 1)\n",
    "X_test = X_test.reshape(-1, 24, 14, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-velvet",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        ConvLSTM2D(filters=32, kernel_size=(3, 1), activation=\"relu\", padding=\"same\", input_shape=(time_steps, X_train.shape[2], X_train.shape[3], 1)),\n",
    "        MaxPooling2D(2),\n",
    "        LeakyReLU(),\n",
    "        Flatten(),\n",
    "        RepeatVector(1),\n",
    "        LSTM(128, activation=\"relu\", return_sequences=True),\n",
    "        LSTM(64, activation=\"relu\", return_sequences=True),\n",
    "        TimeDistributed(Dense(128, activation=\"relu\")),\n",
    "        TimeDistributed(Dense(1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=\"Adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_learning = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=4, min_lr=0)\n",
    "eary_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=7, verbose=1, mode=\"auto\")\n",
    "callbacks = [reduce_learning, eary_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=50,\n",
    "    batch_size=48,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    verbose=1,\n",
    "    shuffle=False,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs_graph = np.arange(1, len(loss) + 1)\n",
    "\n",
    "x_ticks = np.arange(0, len(loss) + 1, 5)\n",
    "x_ticks = np.insert(x_ticks, 1, 1)\n",
    "x_ticks = np.insert(x_ticks, len(x_ticks), len(loss))\n",
    "\n",
    "plt.xticks(x_ticks)\n",
    "plt.xlim(1, len(loss))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(epochs_graph, loss, \"red\", label=\"Training loss\")\n",
    "plt.plot(epochs_graph, val_loss, \"blue\", label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"Models/UCID_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"Models/UCID_Model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = model.predict(X_test)\n",
    "Predictions = scaler.inverse_transform(Predictions.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0540cb0-5ae0-4b57-814d-432a11342d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_Pred = s_Test[\"Trend\"].to_frame().copy()\n",
    "s_Pred = s_Pred.iloc[time_steps:]\n",
    "s_Pred[s_Pred.columns] = scaler.inverse_transform(s_Pred[s_Pred.columns])\n",
    "s_Pred.insert(len(s_Pred.columns), \"Predictions\", Predictions)\n",
    "s_Pred.index = s_Pred.index.strftime(\"%d-%m-%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "s_Pred.Predictions.plot(ax=ax, label=\"Predictions\")\n",
    "s_Pred.Trend.plot(ax=ax, label=\"Ground truth\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Global Active Power (Kilowatts)\")\n",
    "ax.set_xlim(0, len(s_Pred))\n",
    "fig.autofmt_xdate()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "forecast_accuracy(s_Pred.Predictions.ravel(), s_Pred.Trend.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963da56e-6942-4757-b27f-6712798ab913",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = to_Supervised_ms(s_Train.values, lag=24, n_ahead=12, target_index=len(s_Train.columns) - 1)\n",
    "X_val, Y_val = to_Supervised_ms(s_Val.values, lag=24, n_ahead=12, target_index=len(s_Val.columns) - 1)\n",
    "X_test, Y_test = to_Supervised_ms(s_Test.values, lag=24, n_ahead=12, target_index=len(s_Test.columns) - 1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 24, 14, 2, 1)\n",
    "X_val = X_val.reshape(-1, 24, 14, 2, 1)\n",
    "X_test = X_test.reshape(-1, 24, 14, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08298c8c-b699-4b8c-acc4-09e00369a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        ConvLSTM2D(filters=32, kernel_size=(3, 1), activation=\"relu\", padding=\"same\", input_shape=(time_steps, X_train.shape[2], X_train.shape[3], 1)),\n",
    "        MaxPooling2D(2),\n",
    "        LeakyReLU(),\n",
    "        Flatten(),\n",
    "        RepeatVector(1),\n",
    "        LSTM(128, activation=\"relu\", return_sequences=True),\n",
    "        LSTM(64, activation=\"relu\", return_sequences=True),\n",
    "        TimeDistributed(Dense(128, activation=\"relu\")),\n",
    "        TimeDistributed(Dense(12)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=\"Adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02627931-00fe-4aa0-b642-015050063fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=50,\n",
    "    batch_size=48,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    verbose=1,\n",
    "    shuffle=False,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb9d4c-b16e-43db-8ee7-bd1eb1c4ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"Models/UCID_Model_12_Steps_Ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80723bb-74a1-4761-9afe-36fc60bd4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"Models/UCID_Model_12_Steps_Ahead\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b4cb9-efc3-46ff-a5ad-a6972cdd6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbc810-92c1-4b2e-89ea-f0d003508646",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = scaler.inverse_transform(Predictions.reshape(-1, 1))\n",
    "Y_test = scaler.inverse_transform(Y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb125e3c-913a-47f2-a4a4-80d03df9dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_accuracy(Predictions.ravel(), Y_test.ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
